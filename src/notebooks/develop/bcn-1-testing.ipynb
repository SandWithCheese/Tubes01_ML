{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthcheck\n"
     ]
    }
   ],
   "source": [
    "from ffnn.healthcheck import healthcheck\n",
    "healthcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ffnn.ffnn import FFNN\n",
    "from ffnn.types import ActivationFunction, LossFunction, WeightInitializer, WeightsSetup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer initialized: 2 -> 2\n",
      "Activation: ActivationFunction.SIGMOID\n",
      "Weights setup: WeightsSetup(initializer=<WeightInitializer.UNIFORM: 2>, lower_bound=0, upper_bound=1, mean=None, variance=None, seed=817)\n",
      "Weight initializer: WeightInitializer.UNIFORM\n",
      "\n",
      "Layer initialized: 2 -> 2\n",
      "Activation: ActivationFunction.SIGMOID\n",
      "Weights setup: WeightsSetup(initializer=<WeightInitializer.NORMAL: 3>, lower_bound=None, upper_bound=None, mean=0, variance=1, seed=817)\n",
      "Weight initializer: WeightInitializer.NORMAL\n",
      "\n",
      "FFNN initialized\n",
      "Layer sizes: [2, 2, 2]\n",
      "Activation functions: [<ActivationFunction.SIGMOID: 3>, <ActivationFunction.SIGMOID: 3>]\n",
      "Loss function: LossFunction.MEAN_SQUARED_ERROR\n",
      "Weights setup: [WeightsSetup(initializer=<WeightInitializer.UNIFORM: 2>, lower_bound=0, upper_bound=1, mean=None, variance=None, seed=817), WeightsSetup(initializer=<WeightInitializer.NORMAL: 3>, lower_bound=None, upper_bound=None, mean=0, variance=1, seed=817)]\n",
      "Learning rate: 0.5\n",
      "Batch size: 32\n",
      "Epochs: 1\n",
      "Verbose: False\n",
      "Random state: 817\n"
     ]
    }
   ],
   "source": [
    "# 2 node di input layer, 3 node di hidden layer, 2 node di output layer\n",
    "layer_sizes = [2, 2, 2]\n",
    "\n",
    "activation_functions = [\n",
    "    ActivationFunction.SIGMOID, \n",
    "    ActivationFunction.SIGMOID,\n",
    "]\n",
    "\n",
    "loss_function = LossFunction.MEAN_SQUARED_ERROR\n",
    "\n",
    "weights_setup = [\n",
    "    WeightsSetup(initializer=WeightInitializer.UNIFORM, lower_bound=0, upper_bound=1, seed=1),\n",
    "    WeightsSetup(initializer=WeightInitializer.NORMAL, mean=0, variance=1, seed=1),\n",
    "]\n",
    "\n",
    "model = FFNN(\n",
    "    layer_sizes=layer_sizes, \n",
    "    activation_functions=activation_functions, \n",
    "    loss_function=loss_function, \n",
    "    weights_setup=weights_setup,\n",
    "    epochs=1,\n",
    "    learning_rate=0.5,\n",
    "    # random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 weights:\n",
      "[[0.15 0.25]\n",
      " [0.2  0.3 ]\n",
      " [0.35 0.35]]\n",
      "\n",
      "Layer 2 weights:\n",
      "[[0.4  0.5 ]\n",
      " [0.45 0.55]\n",
      " [0.6  0.6 ]]\n",
      "\n",
      "Epoch 1/1\n",
      "Loss: 0.28047154558021875\n"
     ]
    }
   ],
   "source": [
    "input_data = np.array([\n",
    "    [0.05, 0.1],\n",
    "])\n",
    "\n",
    "target_data = np.array([\n",
    "    [0.01, 0.99],\n",
    "])\n",
    "\n",
    "model.set_weights([\n",
    "    np.array([\n",
    "        [0.15, 0.25],\n",
    "        [0.20, 0.30],\n",
    "        [0.35, 0.35],\n",
    "    ]),\n",
    "    np.array([\n",
    "        [0.40, 0.50],\n",
    "        [0.45, 0.55],\n",
    "        [0.60, 0.60],\n",
    "    ]),\n",
    "])\n",
    "\n",
    "model.print_weights()\n",
    "\n",
    "model.fit(input_data, target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 weights:\n",
      "[[0.14978134 0.24975114]\n",
      " [0.19956268 0.29950229]\n",
      " [0.34562681 0.34502287]]\n",
      "\n",
      "Layer 2 weights:\n",
      "[[0.35891648 0.51130127]\n",
      " [0.40866619 0.56137012]\n",
      " [0.53075072 0.61904912]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.print_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72844198, 0.77837719]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)\n",
    "X = X / 255.0\n",
    "y = np.eye(10)[y.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21000, 784) (49000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.7)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer initialized: 784 -> 40\n",
      "Activation: ActivationFunction.RELU\n",
      "Weights setup: WeightsSetup(initializer=<WeightInitializer.NORMAL: 3>, lower_bound=None, upper_bound=None, mean=0, variance=1, seed=42)\n",
      "Weight initializer: WeightInitializer.NORMAL\n",
      "\n",
      "Layer initialized: 40 -> 10\n",
      "Activation: ActivationFunction.SIGMOID\n",
      "Weights setup: WeightsSetup(initializer=<WeightInitializer.NORMAL: 3>, lower_bound=None, upper_bound=None, mean=0, variance=1, seed=42)\n",
      "Weight initializer: WeightInitializer.NORMAL\n",
      "\n",
      "FFNN initialized\n",
      "Layer sizes: [784, 40, 10]\n",
      "Activation functions: [<ActivationFunction.RELU: 2>, <ActivationFunction.SIGMOID: 3>]\n",
      "Loss function: LossFunction.MEAN_SQUARED_ERROR\n",
      "Weights setup: [WeightsSetup(initializer=<WeightInitializer.NORMAL: 3>, lower_bound=None, upper_bound=None, mean=0, variance=1, seed=42), WeightsSetup(initializer=<WeightInitializer.NORMAL: 3>, lower_bound=None, upper_bound=None, mean=0, variance=1, seed=42)]\n",
      "Learning rate: 0.01\n",
      "Batch size: 32\n",
      "Epochs: 100\n",
      "Verbose: False\n",
      "Random state: 42\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [784, 40, 10]\n",
    "\n",
    "activation_functions = [\n",
    "    ActivationFunction.RELU,\n",
    "    ActivationFunction.SIGMOID,\n",
    "]\n",
    "\n",
    "loss_function = LossFunction.MEAN_SQUARED_ERROR\n",
    "\n",
    "weights_setup = [\n",
    "    WeightsSetup(initializer=WeightInitializer.NORMAL, mean=0, variance=1, seed=1),\n",
    "    WeightsSetup(initializer=WeightInitializer.NORMAL, mean=0, variance=1, seed=1),\n",
    "]\n",
    "\n",
    "model = FFNN(\n",
    "    layer_sizes=layer_sizes, \n",
    "    activation_functions=activation_functions, \n",
    "    loss_function=loss_function, \n",
    "    weights_setup=weights_setup,\n",
    "    epochs=100,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Loss: 0.5164141695956617\n",
      "Epoch 2/100\n",
      "Loss: 0.516326357318957\n",
      "Epoch 3/100\n",
      "Loss: 0.5162385960013808\n",
      "Epoch 4/100\n",
      "Loss: 0.5161508856032312\n",
      "Epoch 5/100\n",
      "Loss: 0.5160632314144232\n",
      "Epoch 6/100\n",
      "Loss: 0.5159756314759684\n",
      "Epoch 7/100\n",
      "Loss: 0.5158880843106771\n",
      "Epoch 8/100\n",
      "Loss: 0.5158005894322297\n",
      "Epoch 9/100\n",
      "Loss: 0.5157131469091494\n",
      "Epoch 10/100\n",
      "Loss: 0.5156257554293395\n",
      "Epoch 11/100\n",
      "Loss: 0.5155384138799506\n",
      "Epoch 12/100\n",
      "Loss: 0.5154511216721317\n",
      "Epoch 13/100\n",
      "Loss: 0.5153638805185818\n",
      "Epoch 14/100\n",
      "Loss: 0.5152766919545051\n",
      "Epoch 15/100\n",
      "Loss: 0.5151895415012269\n",
      "Epoch 16/100\n",
      "Loss: 0.5151024402890532\n",
      "Epoch 17/100\n",
      "Loss: 0.5150153881508617\n",
      "Epoch 18/100\n",
      "Loss: 0.51492838276421\n",
      "Epoch 19/100\n",
      "Loss: 0.5148414254265112\n",
      "Epoch 20/100\n",
      "Loss: 0.5147545129933523\n",
      "Epoch 21/100\n",
      "Loss: 0.5146676453410621\n",
      "Epoch 22/100\n",
      "Loss: 0.5145808240414997\n",
      "Epoch 23/100\n",
      "Loss: 0.5144940481060518\n",
      "Epoch 24/100\n",
      "Loss: 0.5144073178978122\n",
      "Epoch 25/100\n",
      "Loss: 0.5143206346826117\n",
      "Epoch 26/100\n",
      "Loss: 0.514233994256591\n",
      "Epoch 27/100\n",
      "Loss: 0.5141473802620942\n",
      "Epoch 28/100\n",
      "Loss: 0.5140608078674033\n",
      "Epoch 29/100\n",
      "Loss: 0.5139742764886199\n",
      "Epoch 30/100\n",
      "Loss: 0.5138877847570437\n",
      "Epoch 31/100\n",
      "Loss: 0.5138013345162219\n",
      "Epoch 32/100\n",
      "Loss: 0.5137149289550261\n",
      "Epoch 33/100\n",
      "Loss: 0.5136285627836327\n",
      "Epoch 34/100\n",
      "Loss: 0.5135422356491995\n",
      "Epoch 35/100\n",
      "Loss: 0.5134559497297596\n",
      "Epoch 36/100\n",
      "Loss: 0.5133697007775518\n",
      "Epoch 37/100\n",
      "Loss: 0.5132834873027267\n",
      "Epoch 38/100\n",
      "Loss: 0.5131973083524045\n",
      "Epoch 39/100\n",
      "Loss: 0.5131111641458647\n",
      "Epoch 40/100\n",
      "Loss: 0.5130250561001234\n",
      "Epoch 41/100\n",
      "Loss: 0.5129389912657928\n",
      "Epoch 42/100\n",
      "Loss: 0.5128529574438996\n",
      "Epoch 43/100\n",
      "Loss: 0.5127669505354715\n",
      "Epoch 44/100\n",
      "Loss: 0.5126809717227819\n",
      "Epoch 45/100\n",
      "Loss: 0.5125950213316999\n",
      "Epoch 46/100\n",
      "Loss: 0.5125091017854279\n",
      "Epoch 47/100\n",
      "Loss: 0.5124232117575998\n",
      "Epoch 48/100\n",
      "Loss: 0.5123373507769308\n",
      "Epoch 49/100\n",
      "Loss: 0.5122515245791759\n",
      "Epoch 50/100\n",
      "Loss: 0.5121657263893471\n",
      "Epoch 51/100\n",
      "Loss: 0.5120799517854479\n",
      "Epoch 52/100\n",
      "Loss: 0.511994202236307\n",
      "Epoch 53/100\n",
      "Loss: 0.5119084739033927\n",
      "Epoch 54/100\n",
      "Loss: 0.5118227693965606\n",
      "Epoch 55/100\n",
      "Loss: 0.5117370890413996\n",
      "Epoch 56/100\n",
      "Loss: 0.5116514294917378\n",
      "Epoch 57/100\n",
      "Loss: 0.511565790233493\n",
      "Epoch 58/100\n",
      "Loss: 0.5114801725461048\n",
      "Epoch 59/100\n",
      "Loss: 0.5113945748474974\n",
      "Epoch 60/100\n",
      "Loss: 0.5113089965547084\n",
      "Epoch 61/100\n",
      "Loss: 0.5112234345593017\n",
      "Epoch 62/100\n",
      "Loss: 0.5111378918119366\n",
      "Epoch 63/100\n",
      "Loss: 0.51105236793729\n",
      "Epoch 64/100\n",
      "Loss: 0.5109668640938597\n",
      "Epoch 65/100\n",
      "Loss: 0.5108813783122832\n",
      "Epoch 66/100\n",
      "Loss: 0.5107959084636093\n",
      "Epoch 67/100\n",
      "Loss: 0.5107104555695081\n",
      "Epoch 68/100\n",
      "Loss: 0.5106250200813973\n",
      "Epoch 69/100\n",
      "Loss: 0.5105396039025859\n",
      "Epoch 70/100\n",
      "Loss: 0.5104542044628475\n",
      "Epoch 71/100\n",
      "Loss: 0.5103688199710379\n",
      "Epoch 72/100\n",
      "Loss: 0.5102834501880943\n",
      "Epoch 73/100\n",
      "Loss: 0.5101980939338867\n",
      "Epoch 74/100\n",
      "Loss: 0.5101127555797327\n",
      "Epoch 75/100\n",
      "Loss: 0.5100274341005744\n",
      "Epoch 76/100\n",
      "Loss: 0.5099421277210047\n",
      "Epoch 77/100\n",
      "Loss: 0.5098568381745819\n",
      "Epoch 78/100\n",
      "Loss: 0.5097715633979472\n",
      "Epoch 79/100\n",
      "Loss: 0.509686302952127\n",
      "Epoch 80/100\n",
      "Loss: 0.5096010578669362\n",
      "Epoch 81/100\n",
      "Loss: 0.5095158240339741\n",
      "Epoch 82/100\n",
      "Loss: 0.5094305995944489\n",
      "Epoch 83/100\n",
      "Loss: 0.5093453888023357\n",
      "Epoch 84/100\n",
      "Loss: 0.5092601942093931\n",
      "Epoch 85/100\n",
      "Loss: 0.509175013219329\n",
      "Epoch 86/100\n",
      "Loss: 0.5090898436990551\n",
      "Epoch 87/100\n",
      "Loss: 0.509004683743106\n",
      "Epoch 88/100\n",
      "Loss: 0.508919539505536\n",
      "Epoch 89/100\n",
      "Loss: 0.5088344065684991\n",
      "Epoch 90/100\n",
      "Loss: 0.5087492803229763\n",
      "Epoch 91/100\n",
      "Loss: 0.5086641635740728\n",
      "Epoch 92/100\n",
      "Loss: 0.5085790674943994\n",
      "Epoch 93/100\n",
      "Loss: 0.5084939880842442\n",
      "Epoch 94/100\n",
      "Loss: 0.5084089255579322\n",
      "Epoch 95/100\n",
      "Loss: 0.5083238755438542\n",
      "Epoch 96/100\n",
      "Loss: 0.5082388358502078\n",
      "Epoch 97/100\n",
      "Loss: 0.5081538074768802\n",
      "Epoch 98/100\n",
      "Loss: 0.5080687868047596\n",
      "Epoch 99/100\n",
      "Loss: 0.507983777585913\n",
      "Epoch 100/100\n",
      "Loss: 0.5078987790188219\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 weights:\n",
      "[[ 0.49671415 -0.1382643   0.64768854 ... -1.95967012 -1.32818605\n",
      "   0.19686124]\n",
      " [ 0.73846658  0.17136828 -0.11564828 ... -0.29900735  0.09176078\n",
      "  -1.98756891]\n",
      " [-0.21967189  0.35711257  1.47789404 ... -1.16867804  1.14282281\n",
      "   0.75193303]\n",
      " ...\n",
      " [-1.35563349 -0.03811314 -1.37162607 ...  0.88537699 -0.31350669\n",
      "  -0.58011746]\n",
      " [-0.03929654 -1.34165212 -0.13858198 ... -0.63708118  0.45653317\n",
      "   0.95364896]\n",
      " [-1.31395794 -0.20858697 -0.02477053 ...  0.9405914   0.90737436\n",
      "   1.58001054]]\n",
      "\n",
      "Layer 2 weights:\n",
      "[[ 0.49669307 -0.13841212  0.64736071  1.52265317 -0.23444618 -0.23455915\n",
      "   1.57883474  0.76712604 -0.47007999  0.54177346]\n",
      " [-0.46344871 -0.46625884  0.24157742 -1.91410156 -1.72599139 -0.56336697\n",
      "  -1.01383182  0.31295839 -0.90968927 -1.41339691]\n",
      " [ 1.46549837 -0.22712007  0.06631941 -1.42609427 -0.54743336  0.1086933\n",
      "  -1.15332197  0.37323507 -0.60376189 -0.29434546]\n",
      " [-0.60189124  1.8518962  -0.01766693 -1.06258314  0.81701544 -1.22650342\n",
      "   0.20187139 -1.96385792 -1.33329496  0.19223171]\n",
      " [ 0.7383315   0.16905598 -0.11975852 -0.3064726  -1.48636269 -0.7265139\n",
      "  -0.46930613  1.04954466  0.34011124 -1.77071079]\n",
      " [ 0.32405731 -0.3851131  -0.67733637  0.61129709  1.03079092  0.93081256\n",
      "  -0.83971689 -0.30951748  0.33100086  0.9752268 ]\n",
      " [-0.47928454 -0.18775533 -1.10879077 -1.20011288  0.80660332  1.3492756\n",
      "  -0.07834165  0.99837135  0.35750757 -0.65015832]\n",
      " [ 0.36125141  1.5377807  -0.03676173  1.56347178 -2.62149086  0.82065781\n",
      "   0.08561086 -0.30051556  0.09061456 -1.9887442 ]\n",
      " [-0.21964167  0.3569639   1.4772049  -0.51909007 -0.80937592 -0.50292161\n",
      "   0.91445458  0.3280506  -0.53063129  0.51214092]\n",
      " [ 0.09704693  0.9684323  -0.70304536 -0.32853265 -0.39329776 -1.46524353\n",
      "   0.29485297  0.26113511  0.00448029 -0.23622944]\n",
      " [-1.41544252 -0.42191662 -0.34479847 -0.80508236 -0.16545292  0.4003375\n",
      "   1.88388923  0.16996182  0.25491129 -0.07866269]\n",
      " [-1.91898841 -0.03144977  0.05188244  2.45651153 -0.20725415  0.28478022\n",
      "  -0.04928624 -1.17759903  1.13559823  0.7368919 ]\n",
      " [ 0.79078602 -0.91120496  1.40052775 -1.40472557  0.58303578  2.18598282\n",
      "  -0.99527102 -0.56879036  0.09699721 -0.50728786]\n",
      " [-1.55067564  0.06827948 -1.06328716  0.47251461 -0.92068959  1.54792507\n",
      "  -0.78537897 -0.32354186  0.81214657 -1.23283953]\n",
      " [ 0.22745865  1.30703338 -1.60772561  0.1845637   0.25935833  0.78133551\n",
      "  -1.23744682 -1.32106225  0.52115125  0.29636624]\n",
      " [ 0.25051124  0.34597034 -0.68136213  0.23110703  0.29159573 -0.71538867\n",
      "   1.86456934  0.47221188 -1.19304448  0.65481394]\n",
      " [-0.97484678  0.78533249  1.15376024 -0.82537109  0.95472328  0.40469301\n",
      "   0.81512875  1.89084833 -0.25082753 -0.76127867]\n",
      " [-0.88941997 -0.81610389 -0.07776209  0.34060659  0.27589607  0.82651873\n",
      "   0.01272778  1.45280554 -0.26520365  2.71924657]\n",
      " [ 0.62562262 -0.8584281  -1.07233246  0.48032254 -0.22686167  0.71105219\n",
      "   0.47044928 -0.07563067 -0.84910849 -1.51781484]\n",
      " [-0.44659058  0.8560636   0.21129209 -1.2500361   0.1688129   0.3796064\n",
      "  -0.88947992  0.14946003  0.05506614 -1.14593062]\n",
      " [ 0.35753475  0.55910602  1.0794554   1.04934334 -1.38464883 -0.9420694\n",
      "   0.50880842  0.50791038  0.51192879  3.84879967]\n",
      " [ 0.5708115   1.13472403  0.94878998  0.64707941 -0.32014877  0.75062187\n",
      "  -0.77981295 -0.24108964 -0.48928152  0.07522332]\n",
      " [ 2.31482043 -1.86773203  0.68547252 -1.61382026 -0.47304296  1.08793387\n",
      "   0.06370955 -1.07871515 -0.7161204   0.67827529]\n",
      " [-0.73023223  0.21488646  0.04183978 -0.65529929  2.13726983  0.62767886\n",
      "  -2.0321864   0.181877   -0.66767164  0.84670578]\n",
      " [-0.79249306 -0.11640542  0.50136079  0.86218666 -1.20488112 -0.34014384\n",
      "  -0.48232509 -0.65697452  1.76379579  0.39915578]\n",
      " [-1.26088394  0.91738708  2.1194264   1.03045434 -1.52185235 -0.48753078\n",
      "   1.26386696 -0.70939142  0.44171376  0.77148341]\n",
      " [-0.92706004 -0.06393816 -3.24736612 -1.03142534 -0.26574032 -1.2598929\n",
      "   1.61951882 -1.43971507 -0.44881845  0.11837023]\n",
      " [ 1.44079385 -1.43679533  1.16163035  0.0083564  -0.98330621  0.45876244\n",
      "   0.19623835 -0.60226292  0.06797637 -0.38720437]\n",
      " [ 0.11364874  0.66194553  1.58440009 -1.23997978  2.13120157 -1.95307969\n",
      "  -0.15313782  0.58647313  0.27946711 -0.62489975]\n",
      " [-0.20809574 -0.49360099 -0.59085363  0.84849319  0.35521194 -0.69417424\n",
      "   0.89857704  0.30604229  0.81237759  0.6280002 ]\n",
      " [-0.82907898 -0.56151786  0.74453223  0.6082039  -0.02532691  0.11237237\n",
      "   1.27404181 -0.59313887  0.54445524 -0.20668095]\n",
      " [-0.21761195  1.09812784  0.82197963  0.81084268  1.30188214  0.01719178\n",
      "   0.67842408 -0.31395743  0.32094894 -0.13419433]\n",
      " [ 0.09686194  0.59413319 -0.82037391  2.09113788 -1.00955309 -1.21740461\n",
      "   1.15504648  0.78786047  0.62069405  0.62404805]\n",
      " [-0.01227121 -0.89731413  0.07561223 -0.67742963  0.9750665  -0.14732741\n",
      "  -0.82586833 -0.32159454  0.41262449 -0.56395714]\n",
      " [-0.82226269  0.24278734  0.24355158 -0.5092672  -0.47404045  0.22929703\n",
      "  -1.45028966 -1.40994359 -0.7203253  -0.21574872]\n",
      " [ 0.31091459  1.47514679  0.8568604  -0.16099725 -0.0204048  -1.00342819\n",
      "  -0.02012428 -0.28959775  0.32230432 -0.82855222]\n",
      " [ 0.51919734  1.53217139 -0.11138664  0.39848921  0.68649072 -0.40667561\n",
      "   0.22021719  0.00870073  0.09470777 -0.77724399]\n",
      " [ 0.02464333  0.49726584  1.44865646  0.9572697   2.14925642 -0.7703141\n",
      "   0.86913402  0.18117765  2.18886932 -0.81126714]\n",
      " [-0.83979415 -0.60116489 -2.12693119 -0.52888752 -0.76407016  0.14541028\n",
      "   0.33677004  1.87321368  0.94822397 -0.5810326 ]\n",
      " [-0.89848888  0.49112077 -1.3228557   1.82856968  1.17337625 -0.4739362\n",
      "  -1.72008628  1.34935348 -0.11786267  1.23338888]\n",
      " [-1.59444943 -0.59965319  0.00464196  0.04633469 -0.45109495  0.62188751\n",
      "  -1.06867661 -0.14313189  0.11956417  0.51347727]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.print_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.58826627e-36, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 9.98189768e-01, 1.00000000e+00, 2.23223595e-10,\n",
       "        1.00000000e+00, 4.53986779e-26],\n",
       "       [7.13019308e-23, 1.00000000e+00, 9.99999998e-01, 9.99956815e-01,\n",
       "        1.00000000e+00, 9.99100876e-01, 1.71534743e-07, 1.65839865e-16,\n",
       "        6.94406126e-01, 6.58146099e-13],\n",
       "       [6.23827421e-25, 9.99999997e-01, 6.45365108e-34, 9.99996209e-01,\n",
       "        2.48362332e-08, 4.39258996e-20, 1.00000000e+00, 9.99968772e-01,\n",
       "        1.00000000e+00, 9.99995843e-01],\n",
       "       [6.12614406e-13, 1.00000000e+00, 1.00000000e+00, 9.99999990e-01,\n",
       "        9.99719875e-01, 8.84495859e-06, 1.05992301e-11, 7.27674001e-09,\n",
       "        9.99999997e-01, 1.00000000e+00],\n",
       "       [1.14750844e-30, 1.00000000e+00, 5.92321841e-01, 9.99999700e-01,\n",
       "        1.00000000e+00, 9.99999996e-01, 1.00000000e+00, 3.90412933e-02,\n",
       "        9.99999964e-01, 1.00000000e+00],\n",
       "       [7.29112891e-25, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        9.99999997e-01, 9.99633909e-01, 7.17266467e-09, 7.88931777e-23,\n",
       "        1.00000000e+00, 1.85854106e-07],\n",
       "       [1.79556041e-31, 1.00000000e+00, 9.99839045e-01, 1.00000000e+00,\n",
       "        8.11644802e-01, 7.03586778e-02, 9.99999998e-01, 4.13073963e-14,\n",
       "        1.00000000e+00, 8.15285254e-01],\n",
       "       [1.80172930e-36, 1.00000000e+00, 1.13881480e-16, 1.00000000e+00,\n",
       "        2.85296733e-05, 5.59121876e-33, 1.00000000e+00, 5.21207259e-01,\n",
       "        1.00000000e+00, 1.00000000e+00],\n",
       "       [3.39745825e-24, 1.00000000e+00, 1.45956747e-07, 1.29791461e-05,\n",
       "        9.99824869e-01, 1.71014721e-06, 8.98857620e-02, 9.99997704e-01,\n",
       "        6.90704502e-01, 3.55726483e-07],\n",
       "       [5.42214394e-28, 9.99999999e-01, 1.20806617e-04, 1.00000000e+00,\n",
       "        9.99999997e-01, 9.68401524e-02, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.00000000e+00, 9.99999797e-01]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0936530612244898\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_true = y_test\n",
    "\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "accuracy = np.mean(y_pred == y_true)\n",
    "\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
